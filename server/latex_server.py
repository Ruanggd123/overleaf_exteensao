#!/usr/bin/env python3
"""
Servidor LaTeX para Cloud (Cloud Run/AWS ECS) com conversÃ£o para Word

Endpoints:
  POST /compile      â€” Compila arquivos .tex enviados como JSON
  POST /compile-zip  â€” Compila projeto enviado como ZIP
  POST /compile-delta â€” Compila apenas mudanÃ§as (delta)
  POST /convert/word â€” Converte PDF para DOCX usando LibreOffice/pandoc
  GET  /status       â€” Health check
  GET  /             â€” PÃ¡gina de status/landing

Deploy:
  - Google Cloud Run: gcloud run deploy --source .
  - AWS ECS: Use o Dockerfile com Fargate
"""

import os
import sys
import io
import shutil
import tempfile
import zipfile
import subprocess
import traceback
import json
from pathlib import Path
from functools import wraps

from flask import Flask, request, send_file, jsonify, render_template_string
from flask_cors import CORS

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Configuration (Cloud-Optimized)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SUPPORTED_ENGINES = ['pdflatex', 'xelatex', 'lualatex']
DEFAULT_ENGINE = os.environ.get('LATEX_ENGINE', 'pdflatex')
BIBTEX_CMD = 'bibtex'
COMPILE_TIMEOUT = int(os.environ.get('COMPILE_TIMEOUT', '300'))
PORT = int(os.environ.get('PORT', '8080'))
AUTH_TOKEN = os.environ.get('AUTH_TOKEN')  # ObrigatÃ³rio em produÃ§Ã£o!
MAX_REQUEST_SIZE = int(os.environ.get('MAX_REQUEST_SIZE', '50'))  # MB

# Cloud storage para cache (opcional)
USE_CLOUD_STORAGE = os.environ.get('USE_CLOUD_STORAGE', 'false').lower() == 'true'
if USE_CLOUD_STORAGE:
    try:
        from google.cloud import storage
        GCS_BUCKET = os.environ.get('GCS_BUCKET')
        storage_client = storage.Client()
        print(f"[Cloud] Google Cloud Storage ativado: {GCS_BUCKET}")
    except ImportError:
        USE_CLOUD_STORAGE = False
        print("[Cloud] google-cloud-storage nÃ£o instalado, usando disco local")

app = Flask(__name__)
CORS(app, resources={
    r"/*": {
        "origins": "*",  # Em produÃ§Ã£o, restrinja para seus domÃ­nios
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Authorization", "Content-Type"]
    }
})

# Limitar tamanho do upload
app.config['MAX_CONTENT_LENGTH'] = MAX_REQUEST_SIZE * 1024 * 1024

# Cache para projetos (para compilaÃ§Ã£o delta)
project_cache = {}  # projectId -> {files, timestamp}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Cloud Storage Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def upload_to_gcs(local_path, destination_blob_name):
    """Upload arquivo para Google Cloud Storage."""
    if not USE_CLOUD_STORAGE:
        return None
    try:
        bucket = storage_client.bucket(GCS_BUCKET)
        blob = bucket.blob(destination_blob_name)
        blob.upload_from_filename(local_path)
        return blob.public_url
    except Exception as e:
        print(f"[GCS] Erro no upload: {e}")
        return None

def download_from_gcs(source_blob_name, destination_path):
    """Download arquivo do Google Cloud Storage."""
    if not USE_CLOUD_STORAGE:
        return False
    try:
        bucket = storage_client.bucket(GCS_BUCKET)
        blob = bucket.blob(source_blob_name)
        blob.download_to_filename(destination_path)
        return True
    except Exception as e:
        print(f"[GCS] Erro no download: {e}")
        return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Security & Error Handling
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.errorhandler(Exception)
def handle_exception(e):
    tb = traceback.format_exc()
    print(f'[ERROR] {e}')
    print(tb)
    return jsonify({
        'error': f'Erro interno: {str(e)}',
        'log': tb[-3000:] if os.environ.get('DEBUG') else 'Erro interno do servidor'
    }), 500

@app.errorhandler(413)
def handle_too_large(e):
    return jsonify({'error': f'Arquivo muito grande (limite: {MAX_REQUEST_SIZE}MB).'}), 413

def require_auth(f):
    """Decorator para exigir autenticaÃ§Ã£o em produÃ§Ã£o."""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if AUTH_TOKEN:
            auth = request.headers.get('Authorization')
            if not auth or auth != f'Bearer {AUTH_TOKEN}':
                return jsonify({'error': 'Unauthorized - Token invÃ¡lido ou ausente'}), 401
        return f(*args, **kwargs)
    return decorated_function

def check_origin():
    """Verifica origem da requisiÃ§Ã£o (proteÃ§Ã£o bÃ¡sica)."""
    allowed_origins = os.environ.get('ALLOWED_ORIGINS', '').split(',')
    origin = request.headers.get('Origin', '')
    if allowed_origins and allowed_origins[0] and origin not in allowed_origins:
        return jsonify({'error': 'Origin not allowed'}), 403
    return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Utility Functions (Mesmas funÃ§Ãµes, otimizadas para cloud)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_available_engines():
    """Detecta motores LaTeX disponÃ­veis."""
    available = []
    for eng in SUPPORTED_ENGINES:
        if shutil.which(eng):
            available.append(eng)
    return available

def find_main_file(directory):
    """Encontra arquivo .tex principal."""
    tex_files = list(Path(directory).rglob('*.tex'))
    
    if not tex_files:
        return None
    
    # Prioridade: main.tex na raiz
    for f in tex_files:
        if f.name.lower() == 'main.tex' and f.parent == Path(directory):
            return str(f.relative_to(directory))
    
    # Qualquer main.tex
    for f in tex_files:
        if f.name.lower() == 'main.tex':
            return str(f.relative_to(directory))
    
    # Arquivo com \documentclass
    for f in tex_files:
        try:
            content = f.read_text(encoding='utf-8', errors='ignore')
            if '\\documentclass' in content:
                return str(f.relative_to(directory))
        except Exception:
            continue
    
    # Fallback: primeiro .tex
    return str(tex_files[0].relative_to(directory))

def compile_project(directory, main_file, engine=None, project_id=None):
    """
    Pipeline de compilaÃ§Ã£o LaTeX otimizado para cloud.
    """
    engine = engine if engine in SUPPORTED_ENGINES else DEFAULT_ENGINE
    
    if not shutil.which(engine):
        return {
            'success': False,
            'log': f'Motor LaTeX "{engine}" nÃ£o encontrado.',
        }
    
    main_path = os.path.join(directory, main_file)
    if not os.path.isfile(main_path):
        return {
            'success': False,
            'log': f'Arquivo principal nÃ£o encontrado: {main_file}',
        }
    
    work_dir = os.path.dirname(main_path) or directory
    main_basename = os.path.basename(main_file)
    
    base_cmd = [engine, '-interaction=nonstopmode', '-file-line-error',
                '-enable-installer', main_basename]
    
    env = os.environ.copy()
    env['MIKTEX_ENABLEINSTALLER'] = 't'
    env['TEXMFVAR'] = '/tmp/texmf-var'  # Evita problemas de permissÃ£o
    
    full_log = ''
    print(f'[Cloud Compile] Engine: {engine}, Main: {main_file}')
    
    try:
        # Passo 1
        print('[Cloud Compile] Pass 1...')
        r1 = subprocess.run(
            base_cmd, cwd=work_dir, capture_output=True, text=True,
            timeout=COMPILE_TIMEOUT, env=env,
        )
        full_log += r1.stdout + '\n' + r1.stderr
        
        needs_bib = False
        needs_rerun = 'Rerun to get cross-references right' in r1.stdout
        
        aux_path = os.path.join(work_dir, os.path.splitext(main_basename)[0] + '.aux')
        if os.path.isfile(aux_path):
            try:
                aux_content = open(aux_path, 'r', encoding='utf-8', errors='ignore').read()
                needs_bib = '\\citation' in aux_content or '\\bibdata' in aux_content
            except Exception:
                pass
        
        # BibTeX
        if needs_bib and shutil.which(BIBTEX_CMD):
            bib_base = os.path.splitext(main_basename)[0]
            print('[Cloud Compile] Running BibTeX...')
            rb = subprocess.run(
                [BIBTEX_CMD, bib_base], cwd=work_dir, capture_output=True,
                text=True, timeout=60, env=env,
            )
            full_log += '\n--- BibTeX ---\n' + rb.stdout + '\n' + rb.stderr
            needs_rerun = True
        
        # Passos 2 e 3
        if needs_rerun:
            for i in range(2):
                print(f'[Cloud Compile] Pass {i + 2}...')
                ri = subprocess.run(
                    base_cmd, cwd=work_dir, capture_output=True, text=True,
                    timeout=COMPILE_TIMEOUT, env=env,
                )
                full_log += f'\n--- Pass {i + 2} ---\n' + ri.stdout + '\n' + ri.stderr
                if 'Rerun to get cross-references right' not in ri.stdout:
                    break
        
        # Verificar resultado
        actual_pdf = os.path.join(work_dir, os.path.splitext(main_basename)[0] + '.pdf')
        if os.path.isfile(actual_pdf):
            size_mb = os.path.getsize(actual_pdf) / (1024 * 1024)
            print(f'[Cloud Compile] [OK] PDF gerado ({size_mb:.1f} MB)')
            
            # Upload para cloud storage se configurado
            public_url = None
            if project_id and USE_CLOUD_STORAGE:
                blob_name = f"projects/{project_id}/output.pdf"
                public_url = upload_to_gcs(actual_pdf, blob_name)
            
            return {
                'success': True, 
                'pdf_path': actual_pdf, 
                'log': full_log,
                'public_url': public_url
            }
        else:
            print('[Cloud Compile] [ERR] PDF nÃ£o gerado')
            return {'success': False, 'log': full_log}
            
    except subprocess.TimeoutExpired:
        return {'success': False, 'log': f'Timeout ({COMPILE_TIMEOUT}s) expirado.'}
    except Exception as e:
        return {'success': False, 'log': f'Erro: {str(e)}'}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  PDF to Word Conversion
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def convert_pdf_to_word(pdf_path):
    """
    Converte PDF para DOCX usando LibreOffice ou pandoc.
    Tenta mÃºltiplas estratÃ©gias em ordem de preferÃªncia.
    """
    output_dir = os.path.dirname(pdf_path)
    base_name = os.path.splitext(os.path.basename(pdf_path))[0]
    docx_path = os.path.join(output_dir, f"{base_name}.docx")
    
    # EstratÃ©gia 1: LibreOffice (melhor qualidade para LaTeX)
    if shutil.which('libreoffice'):
        try:
            print(f'[Convert] Tentando LibreOffice...')
            cmd = [
                'libreoffice', 
                '--headless', 
                '--convert-to', 'docx',
                '--outdir', output_dir,
                pdf_path
            ]
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=60
            )
            if result.returncode == 0 and os.path.isfile(docx_path):
                print(f'[Convert] LibreOffice sucesso: {docx_path}')
                return docx_path
            else:
                print(f'[Convert] LibreOffice falhou: {result.stderr}')
        except Exception as e:
            print(f'[Convert] LibreOffice erro: {e}')
    
    # EstratÃ©gia 2: Pandoc (se disponÃ­vel)
    if shutil.which('pandoc'):
        try:
            print(f'[Convert] Tentando pandoc...')
            # Pandoc funciona melhor com LaTeX direto, mas tentamos PDF
            cmd = [
                'pandoc',
                '-f', 'pdf',
                '-t', 'docx',
                '-o', docx_path,
                pdf_path
            ]
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode == 0 and os.path.isfile(docx_path):
                print(f'[Convert] Pandoc sucesso: {docx_path}')
                return docx_path
            else:
                print(f'[Convert] Pandoc falhou: {result.stderr}')
        except Exception as e:
            print(f'[Convert] Pandoc erro: {e}')
    
    # EstratÃ©gia 3: pdf2docx (biblioteca Python)
    try:
        from pdf2docx import Converter
        print(f'[Convert] Tentando pdf2docx...')
        cv = Converter(pdf_path)
        cv.convert(docx_path, start=0, end=None)
        cv.close()
        if os.path.isfile(docx_path):
            print(f'[Convert] pdf2docx sucesso: {docx_path}')
            return docx_path
    except ImportError:
        print('[Convert] pdf2docx nÃ£o instalado')
    except Exception as e:
        print(f'[Convert] pdf2docx erro: {e}')
    
    return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Endpoints
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LANDING_PAGE = """
<!DOCTYPE html>
<html>
<head>
    <title>Overleaf Cloud Compiler</title>
    <style>
        body { font-family: system-ui, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; }
        .status { padding: 20px; border-radius: 8px; background: #f0f9ff; border: 1px solid #0ea5e9; }
        .ok { color: #059669; }
        code { background: #f1f5f9; padding: 2px 6px; border-radius: 4px; }
    </style>
</head>
<body>
    <h1>ğŸš€ Overleaf Cloud Compiler</h1>
    <div class="status">
        <h2>Status do Servidor</h2>
        <p><strong>Status:</strong> <span class="ok">âœ“ Online</span></p>
        <p><strong>Motores disponÃ­veis:</strong> {{ engines|join(', ') }}</p>
        <p><strong>VersÃ£o:</strong> 2.1.0-cloud</p>
    </div>
    <h2>Endpoints</h2>
    <ul>
        <li><code>GET /status</code> - Health check</li>
        <li><code>POST /compile</code> - Compilar arquivos JSON</li>
        <li><code>POST /compile-zip</code> - Compilar ZIP</li>
        <li><code>POST /compile-delta</code> - CompilaÃ§Ã£o incremental (delta)</li>
        <li><code>POST /convert/word</code> - Converter PDF para DOCX</li>
    </ul>
    <p><em>Para uso com a extensÃ£o Chrome, configure a URL deste servidor.</em></p>
</body>
</html>
"""

@app.route('/')
def index():
    """PÃ¡gina inicial com status."""
    engines = detect_available_engines()
    return render_template_string(LANDING_PAGE, engines=engines)

@app.route('/status', methods=['GET'])
def status():
    """Health check endpoint."""
    engines = detect_available_engines()
    return jsonify({
        'status': 'ok',
        'engines': engines,
        'default_engine': DEFAULT_ENGINE,
        'compile_timeout': COMPILE_TIMEOUT,
        'cloud_storage': USE_CLOUD_STORAGE,
        'version': '2.1.0-cloud',
        'features': ['compile', 'compile-zip', 'compile-delta', 'convert-word']
    })

@app.route('/compile', methods=['POST'])
@require_auth
def compile_latex():
    """Compilar arquivos .tex enviados como JSON."""
    origin_check = check_origin()
    if origin_check:
        return origin_check
    
    data = request.get_json(force=True)
    files = data.get('files', {})
    main_file = data.get('mainFile', 'main.tex')
    engine = data.get('engine', DEFAULT_ENGINE)
    project_id = data.get('projectId')
    
    if not files:
        return jsonify({'error': 'Nenhum arquivo recebido.'}), 400
    
    # Usar diretÃ³rio temporÃ¡rio em /tmp (escrita permitida em Cloud Run)
    with tempfile.TemporaryDirectory(dir='/tmp', prefix='olc_') as work_dir:
        # Escrever arquivos
        for filename, content in files.items():
            filepath = os.path.join(work_dir, filename)
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
        
        result = compile_project(work_dir, main_file, engine, project_id)
        
        if result['success']:
            with open(result['pdf_path'], 'rb') as f:
                pdf_data = io.BytesIO(f.read())
            
            response = send_file(
                pdf_data,
                mimetype='application/pdf',
                as_attachment=True,
                download_name='output.pdf'
            )
            
            # Adicionar headers CORS
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response
        else:
            return jsonify({
                'error': 'CompilaÃ§Ã£o falhou.',
                'log': result['log'][-5000:],  # Aumentado para cloud
                'public_url': result.get('public_url')
            }), 500

@app.route('/compile-zip', methods=['POST'])
@require_auth
def compile_zip():
    """Compilar projeto enviado como ZIP."""
    origin_check = check_origin()
    if origin_check:
        return origin_check
    
    if 'project' not in request.files:
        return jsonify({'error': 'Nenhum arquivo ZIP recebido.'}), 400
    
    zip_file = request.files['project']
    engine = request.form.get('engine', DEFAULT_ENGINE)
    project_id = request.form.get('projectId')
    
    with tempfile.TemporaryDirectory(dir='/tmp', prefix='olc_zip_') as tmp_dir:
        extract_dir = os.path.join(tmp_dir, 'project')
        os.makedirs(extract_dir, exist_ok=True)
        
        try:
            with zipfile.ZipFile(zip_file, 'r') as z:
                z.extractall(extract_dir)
        except zipfile.BadZipFile:
            return jsonify({'error': 'Arquivo ZIP invÃ¡lido.'}), 400
        
        main_file = find_main_file(extract_dir)
        if not main_file:
            return jsonify({'error': 'Nenhum arquivo .tex encontrado no ZIP.'}), 400
        
        result = compile_project(extract_dir, main_file, engine, project_id)
        
        if result['success']:
            with open(result['pdf_path'], 'rb') as f:
                pdf_data = io.BytesIO(f.read())
            
            response = send_file(
                pdf_data,
                mimetype='application/pdf',
                as_attachment=True,
                download_name='output.pdf'
            )
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response
        else:
            return jsonify({
                'error': 'CompilaÃ§Ã£o falhou.',
                'log': result['log'][-5000:],
                'public_url': result.get('public_url')
            }), 500

@app.route('/compile-delta', methods=['POST'])
@require_auth
def compile_delta():
    """
    CompilaÃ§Ã£o incremental: aplica mudanÃ§as (delta) a um projeto existente.
    """
    origin_check = check_origin()
    if origin_check:
        return origin_check
    
    if 'delta_zip' not in request.files:
        return jsonify({'error': 'Nenhum delta ZIP recebido.'}), 400
    
    delta_file = request.files['delta_zip']
    deleted_files = json.loads(request.form.get('deleted_files', '[]'))
    project_id = request.form.get('projectId', '')
    engine = request.form.get('engine', DEFAULT_ENGINE)
    
    if not project_id:
        return jsonify({'error': 'projectId Ã© obrigatÃ³rio para compilaÃ§Ã£o delta.'}), 400
    
    # Verificar se temos o projeto em cache
    if project_id not in project_cache:
        return jsonify({'error': 'CACHE_MISS', 'message': 'Projeto nÃ£o encontrado no cache.'}), 410
    
    cache_info = project_cache[project_id]
    project_dir = cache_info['directory']
    
    # Verificar se diretÃ³rio ainda existe
    if not os.path.exists(project_dir):
        del project_cache[project_id]
        return jsonify({'error': 'CACHE_MISS', 'message': 'DiretÃ³rio de cache nÃ£o existe mais.'}), 410
    
    try:
        # Aplicar deleÃ§Ãµes
        for filepath in deleted_files:
            full_path = os.path.join(project_dir, filepath)
            if os.path.exists(full_path):
                os.remove(full_path)
                print(f'[Delta] Deletado: {filepath}')
        
        # Aplicar atualizaÃ§Ãµes do delta
        with zipfile.ZipFile(delta_file, 'r') as z:
            z.extractall(project_dir)
        
        # Recompilar
        main_file = cache_info.get('main_file') or find_main_file(project_dir)
        if not main_file:
            return jsonify({'error': 'Nenhum arquivo .tex encontrado.'}), 400
        
        # Atualizar cache
        project_cache[project_id]['main_file'] = main_file
        project_cache[project_id]['timestamp'] = os.time()
        
        result = compile_project(project_dir, main_file, engine, project_id)
        
        if result['success']:
            with open(result['pdf_path'], 'rb') as f:
                pdf_data = io.BytesIO(f.read())
            
            response = send_file(
                pdf_data,
                mimetype='application/pdf',
                as_attachment=True,
                download_name='output.pdf'
            )
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response
        else:
            return jsonify({
                'error': 'CompilaÃ§Ã£o falhou.',
                'log': result['log'][-5000:]
            }), 500
            
    except Exception as e:
        return jsonify({'error': f'Erro ao aplicar delta: {str(e)}'}), 500

@app.route('/convert/word', methods=['POST'])
@require_auth
def convert_word():
    """
    Converte PDF para DOCX.
    Recebe arquivo PDF, retorna DOCX.
    """
    origin_check = check_origin()
    if origin_check:
        return origin_check
    
    if 'pdf' not in request.files:
        return jsonify({'error': 'Nenhum arquivo PDF recebido.'}), 400
    
    pdf_file = request.files['pdf']
    
    with tempfile.TemporaryDirectory(dir='/tmp', prefix='olc_convert_') as tmp_dir:
        pdf_path = os.path.join(tmp_dir, 'input.pdf')
        pdf_file.save(pdf_path)
        
        # Converter
        docx_path = convert_pdf_to_word(pdf_path)
        
        if docx_path and os.path.isfile(docx_path):
            with open(docx_path, 'rb') as f:
                docx_data = io.BytesIO(f.read())
            
            response = send_file(
                docx_data,
                mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                as_attachment=True,
                download_name='documento.docx'
            )
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response
        else:
            return jsonify({
                'error': 'ConversÃ£o falhou. Verifique se LibreOffice ou pandoc estÃ£o instalados.'
            }), 500

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    engines = detect_available_engines()
    
    print('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')
    print('â•‘     Overleaf Cloud Compiler v2.1                          â•‘')
    print('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£')
    print(f'  Port:      {PORT}')
    print(f'  Engine:    {DEFAULT_ENGINE}')
    print(f'  Motores:   {", ".join(engines) if engines else "NENHUM!"}')
    print(f'  Timeout:   {COMPILE_TIMEOUT}s')
    print(f'  Max Size:  {MAX_REQUEST_SIZE}MB')
    print(f'  Auth:      {"Ativo" if AUTH_TOKEN else "Desativado"}')
    print(f'  Cloud:     {"GCS" if USE_CLOUD_STORAGE else "Disco local"}')
    print('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
    
    if not engines:
        print('âš ï¸  AVISO: Nenhum motor LaTeX encontrado!')
        print('   Certifique-se de que o Dockerfile estÃ¡ usando texlive/texlive:latest-full')
    
    # Em produÃ§Ã£o, nÃ£o use debug=True
    app.run(host='0.0.0.0', port=PORT, debug=False)
